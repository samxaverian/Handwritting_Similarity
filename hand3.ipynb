{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import os\n",
    "import sys\n",
    "net = cv2.dnn.readNet('frozen_east_text_detection.pb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_knn(image):\n",
    "    data = np.reshape(image,(image.shape[0]*image.shape[1],3))\n",
    "    data = np.float32(data)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 2\n",
    "    ret,label,center=cv2.kmeans(data,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape(image.shape)\n",
    "    res3 = cv2.cvtColor(res2,cv2.COLOR_BGR2GRAY)\n",
    "    _, threshold = cv2.threshold(res3, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    output = cv2.merge([threshold,threshold,threshold])\n",
    "\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text_region(image):\n",
    " \n",
    "\torig = image.copy()\n",
    "\t(H, W) = image.shape[:2]\n",
    "\n",
    "# set the new width and height and then determine the ratio in change\n",
    "# for both the width and height\n",
    "\tnewW, newH = 320, 320\n",
    "\trW = W / float(newW)\n",
    "\trH = H / float(newH)\n",
    "\n",
    "# resize the image and grab the new image dimensions\n",
    "\timage = cv2.resize(image, (newW, newH))\n",
    "\t(H, W) = image.shape[:2]\n",
    "\tlayerNames = [\n",
    "\t\"feature_fusion/Conv_7/Sigmoid\",\n",
    "\t\"feature_fusion/concat_3\"]\n",
    "\tblob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "\t(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "\tnet.setInput(blob)\n",
    "\t(scores, geometry) = net.forward(layerNames)\n",
    "\t(numRows, numCols) = scores.shape[2:4]\n",
    "\trects = []\n",
    "\tconfidences = []\n",
    "\tdetections =[]\n",
    "\n",
    "\n",
    "\tfor y in range(0, numRows):\n",
    "\t\t# extract the scores (probabilities), followed by the geometrical\n",
    "\t\t# data used to derive potential bounding box coordinates that\n",
    "\t\t# surround text\n",
    "\t\tscoresData = scores[0, 0, y]\n",
    "\t\txData0 = geometry[0, 0, y]\n",
    "\t\txData1 = geometry[0, 1, y]\n",
    "\t\txData2 = geometry[0, 2, y]\n",
    "\t\txData3 = geometry[0, 3, y]\n",
    "\t\tanglesData = geometry[0, 4, y]\n",
    "\n",
    "\t\t# loop over the number of columns\n",
    "\t\tfor x in range(0, numCols):\n",
    "\t\t\t# if our score does not have sufficient probability, ignore it\n",
    "\t\t\tif scoresData[x] < 0.5:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t# compute the offset factor as our resulting feature maps will\n",
    "\t\t\t# be 4x smaller than the input image\n",
    "\t\t\t(offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "\t\t\t# extract the rotation angle for the prediction and then\n",
    "\t\t\t# compute the sin and cosine\n",
    "\t\t\tangle = anglesData[x]\n",
    "\t\t\tcos = np.cos(angle)\n",
    "\t\t\tsin = np.sin(angle)\n",
    "\n",
    "\t\t\t# use the geometry volume to derive the width and height of\n",
    "\t\t\t# the bounding box\n",
    "\t\t\th = xData0[x] + xData2[x]\n",
    "\t\t\tw = xData1[x] + xData3[x]\n",
    "\n",
    "\t\t\t# compute both the starting and ending (x, y)-coordinates for\n",
    "\t\t\t# the text prediction bounding box\n",
    "\t\t\tendX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "\t\t\tendY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "\t\t\tstartX = int(endX - w)\n",
    "\t\t\tstartY = int(endY - h)\n",
    "\n",
    "\t\t\t# add the bounding box coordinates and probability score to\n",
    "\t\t\t# our respective lists\n",
    "\t\t\trects.append((startX, startY, endX, endY))\n",
    "\t\t\tconfidences.append(scoresData[x])\n",
    "\n",
    "\t# apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "\t# boxes\n",
    "\tif len(rects)==0:\n",
    "\t\treturn None\n",
    "\tboxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "\t\n",
    "\tfor (startX, startY, endX, endY) in boxes:\n",
    "\t# scale the bounding box coordinates based on the respective\n",
    "\t# ratios\n",
    "\t\tstartX = int(startX * rW)\n",
    "\t\tstartY = int(startY * rH)\n",
    "\t\tendX = int(endX * rW)\n",
    "\t\tendY = int(endY * rH)\n",
    "\n",
    "\t\tdetections.append([startY,endY,startX,endX])\n",
    "  \n",
    "\treturn detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_east = pd.DataFrame(columns=[\"filename\",\"folder\",\"imagename\",\"cropped\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders =[]\n",
    "for folder_name, subs, filenames in os.walk('./dataset/train/'):\n",
    "        # Print the subfolder name\n",
    "        # print(f\"Subfolder: {subfolders}\")\n",
    "        subfolders.extend(subs)\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Train folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "input_path = './dataset/train/'\n",
    "output_path = './hand_east/train/'\n",
    "for x in tqdm(subfolders):\n",
    "    file_path = input_path + x\n",
    "    for _, _, filenames in os.walk(file_path):\n",
    "        for f in filenames:\n",
    "            total += 1\n",
    "            img = file_path+'/'+f\n",
    "            image1 = cv2.imread(img)\n",
    "            image_knn = to_knn(image1)\n",
    "            ci = detect_text_region(image_knn)\n",
    "            if ci:\n",
    "                count1 += 1\n",
    "                arr = np.array(ci)\n",
    "                m_max = arr.max(axis=0)\n",
    "                m_min = arr.min(axis=0)\n",
    "                min_y = m_min[0]\n",
    "                max_y = m_max[1]\n",
    "                min_x = m_min[2]\n",
    "                max_x = m_max[3]\n",
    "                cropped = image_knn[min_y:max_y,min_x:max_x]\n",
    "                if(cropped.shape[0]>50 and cropped.shape[1]>500):\n",
    "                    count2 += 1\n",
    "                    outimg = cropped[0:,100:500]\n",
    "                    resized = cv2.resize(outimg,(256,256))\n",
    "                    newdir = output_path + x\n",
    "                    if not os.path.exists(newdir):\n",
    "                        os.makedirs(newdir)\n",
    "                    opg = newdir + \"/\" + f\n",
    "                    cv2.imwrite(opg,resized)\n",
    "                    data_east.loc[len(data_east)] = [img,x,f,opg]\n",
    "            if(total%100==0):\n",
    "                print(f\"total: {total}, count1: {count1}, count2: {count2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in tqdm(subfolders):\n",
    "    file_path = input_path + x\n",
    "    for y, z, filenames in os.walk(file_path):\n",
    "        print(filenames)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 =[]\n",
    "for folder_name, subs, filenames in os.walk('./hand_east/train/'):\n",
    "        # Print the subfolder name\n",
    "        # print(f\"Subfolder: {subfolders}\")\n",
    "        sub2.extend(subs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1328/1328 [00:00<00:00, 34437.36it/s]\n"
     ]
    }
   ],
   "source": [
    "sub3 =[]\n",
    "for x in tqdm(sub2):\n",
    "    file_path = output_path + x\n",
    "    for y, z, filenames in os.walk(file_path):\n",
    "        sub3.append(filenames)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "c =0\n",
    "temp = []\n",
    "for x in sub3:\n",
    "    if(len(x)==1):\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(data_east,'data_east.scv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.read_csv('data_east.scv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>filename</th>\n",
       "      <th>folder</th>\n",
       "      <th>imagename</th>\n",
       "      <th>cropped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./dataset/train/P2369/B4.jpg</td>\n",
       "      <td>P2369</td>\n",
       "      <td>B4.jpg</td>\n",
       "      <td>./hand_east/train/P2369/B4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./dataset/train/P2369/B6.jpg</td>\n",
       "      <td>P2369</td>\n",
       "      <td>B6.jpg</td>\n",
       "      <td>./hand_east/train/P2369/B6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./dataset/train/P2369/B2.jpg</td>\n",
       "      <td>P2369</td>\n",
       "      <td>B2.jpg</td>\n",
       "      <td>./hand_east/train/P2369/B2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./dataset/train/P2369/B0.jpg</td>\n",
       "      <td>P2369</td>\n",
       "      <td>B0.jpg</td>\n",
       "      <td>./hand_east/train/P2369/B0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>./dataset/train/P2369/B1.jpg</td>\n",
       "      <td>P2369</td>\n",
       "      <td>B1.jpg</td>\n",
       "      <td>./hand_east/train/P2369/B1.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      filename folder imagename  \\\n",
       "0           0  ./dataset/train/P2369/B4.jpg  P2369    B4.jpg   \n",
       "1           1  ./dataset/train/P2369/B6.jpg  P2369    B6.jpg   \n",
       "2           2  ./dataset/train/P2369/B2.jpg  P2369    B2.jpg   \n",
       "3           3  ./dataset/train/P2369/B0.jpg  P2369    B0.jpg   \n",
       "4           4  ./dataset/train/P2369/B1.jpg  P2369    B1.jpg   \n",
       "\n",
       "                          cropped  \n",
       "0  ./hand_east/train/P2369/B4.jpg  \n",
       "1  ./hand_east/train/P2369/B6.jpg  \n",
       "2  ./hand_east/train/P2369/B2.jpg  \n",
       "3  ./hand_east/train/P2369/B0.jpg  \n",
       "4  ./hand_east/train/P2369/B1.jpg  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Validation folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = []\n",
    "for _, _, filenames in os.walk('./dataset/val/'):\n",
    "    val_files.extend(filenames)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop_rectangular_box(image):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the contour with the largest area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Get the bounding rectangle of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Crop the image based on the bounding rectangle\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    #cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "    #output = cv2.merge([cropped_image,cropped_image,cropped_image])\n",
    "    \n",
    "    return cropped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730/730 [07:35<00:00,  1.60it/s]\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "temp =[]\n",
    "input_path = './dataset/val/'\n",
    "output_path = './hand_east/val/'\n",
    "\n",
    "for f in tqdm(val_files):\n",
    "    img = input_path + f\n",
    "    image1 = cv2.imread(img)\n",
    "    image_knn = to_knn(image1)\n",
    "    ci = detect_text_region(image_knn)\n",
    "    if ci:\n",
    "        arr = np.array(ci)\n",
    "        m_max = arr.max(axis=0)\n",
    "        m_min = arr.min(axis=0)\n",
    "        min_y = m_min[0]\n",
    "        max_y = m_max[1]\n",
    "        min_x = m_min[2]\n",
    "        max_x = m_max[3]\n",
    "        cropped = image_knn[min_y:max_y,min_x:max_x]\n",
    "        outimg = cropped[0:,100:500]\n",
    "        temp.append(outimg.shape)\n",
    "        if(outimg.shape[0]==0 or outimg.shape[1]==0):\n",
    "            cimage = crop_rectangular_box(image_knn[:,:,0])\n",
    "            outimg = cimage[0:,200:600]\n",
    "            resized = cv2.resize(outimg,(256,256))\n",
    "            newdir = output_path\n",
    "            if not os.path.exists(newdir):\n",
    "                os.makedirs(newdir)\n",
    "            opg = newdir + f\n",
    "            cv2.imwrite(opg,resized)\n",
    "            continue\n",
    "        resized = cv2.resize(outimg,(256,256))\n",
    "        newdir = output_path\n",
    "        if not os.path.exists(newdir):\n",
    "            os.makedirs(newdir)\n",
    "        opg = newdir + f\n",
    "        cv2.imwrite(opg,resized)\n",
    "    else:\n",
    "\n",
    "        cimage = crop_rectangular_box(image_knn[:,:,0])\n",
    "        outimg = cimage[0:,200:600]\n",
    "        resized = cv2.resize(outimg,(256,256))\n",
    "        newdir = output_path\n",
    "        if not os.path.exists(newdir):\n",
    "            os.makedirs(newdir)\n",
    "        opg = newdir + f\n",
    "        cv2.imwrite(opg,resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(80, 0, 3)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_east = pd.read_csv('hand_east/data_east.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pairs = pd.DataFrame(columns=['img0','img1','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x in subfolders:\n",
    "    df1 = data_east[data_east['folder']==x]\n",
    "    if(len(df1)>1):\n",
    "        for i in range(len(df1)):\n",
    "            for j in range(len(df1)):\n",
    "                if(i!=j):\n",
    "                    xi = df1['cropped'].iloc[i]\n",
    "                    xj = df1['cropped'].iloc[j]\n",
    "                    data_pairs.loc[len(data_pairs)] = [xi,xj,1]\n",
    "                    count += 1\n",
    "                    if(count%1000==0):\n",
    "                        print(count)\n",
    "    df2 = data_east[data_east['folder']!=x]\n",
    "    for i in range(len(df1)):\n",
    "        for j in range(len(df2)):\n",
    "            xi = df1['cropped'].iloc[i]\n",
    "            xj = df2['cropped'].iloc[j]\n",
    "            dx = (data_pairs['img0'] == xj) & (data_pairs['img1'] == xi)\n",
    "            if not dx.any():\n",
    "                data_pairs.loc[len(data_pairs)] = [xi,xj,0]\n",
    "                count += 1\n",
    "                if(count%1000==0):\n",
    "                    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([data_east['folder']=='P2369']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = data_east[data_east['folder']!='P2369']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./hand_east/train/M1042/B3.jpg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['cropped'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1124455 entries, 0 to 1124454\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   img0    1124455 non-null  object\n",
      " 1   img1    1124455 non-null  object\n",
      " 2   label   1124455 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 34.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_pairs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
